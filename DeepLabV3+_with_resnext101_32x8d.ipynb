{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMdqjCfBLSBPf9VCf0eJom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarnavg54/Deep-Learning-Radiomic-Stability/blob/main/DeepLabV3%2B_with_resnext101_32x8d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcQuvTOjspsB"
      },
      "outputs": [],
      "source": [
        "# Installing neccessary libraries\n",
        "!pip install -U segmentation-models-pytorch\n",
        "!pip install -U git+https://github.com/qubvel-org/segmentation_models.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# This function creates a pytorch dataset\n",
        "class HistologyDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx].astype(\"float32\")\n",
        "        mask = self.masks[idx].astype(\"float32\")\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        mask = torch.from_numpy(mask).permute(2, 0, 1)\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "EDAowaius69h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Our preprocessed data\n",
        "import numpy as np\n",
        "X_train = np.load('/content/drive/MyDrive/X_train_ultrasound_images_256_2.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/y_train_ultrasound_images_256_2.npy')\n",
        "X_val = np.load('/content/drive/MyDrive/X_val_ultrasound_images_256_2.npy')\n",
        "y_val = np.load('/content/drive/MyDrive/y_val_ultrasound_images_256_2.npy')\n",
        "X_test = np.load('/content/drive/MyDrive/X_test_ultrasound_images_256_2.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/y_test_ultrasound_images_256_2.npy')\n",
        "\n",
        "train_dataset = HistologyDataset(X_train, y_train)\n",
        "val_dataset = HistologyDataset(X_val, y_val)\n",
        "test_dataset = HistologyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "1w8t8Kjzs8dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "C0FQDVrktGlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing our model from Qubvel's Segmentation Models GitHub repo\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=\"resnext101_32x8d\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        "    activation=None\n",
        ")"
      ],
      "metadata": {
        "id": "KinS1_ECtNW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice loss\n",
        "from segmentation_models_pytorch.losses import DiceLoss\n",
        "import torch.optim as optim\n",
        "\n",
        "dice_loss = DiceLoss(mode='binary', from_logits=True, smooth=1e-5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Setting up the training loop\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "3oOWEDZRtQ17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading our training/ validation/ testing data\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # UPDATED\n",
        "val_loader = DataLoader(val_dataset, batch_size=4)\n",
        "test_loader = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "bCTpbEf9ttwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the number of epochs\n",
        "num_epochs = 500\n",
        "# Early stopping settings\n",
        "patience = 10\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "checkpoint_dir = \"./checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")"
      ],
      "metadata": {
        "id": "Dw0uevdQtvTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looping through all 500 epochs\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = dice_loss(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = dice_loss(outputs, masks)\n",
        "            val_losses.append(loss.item())\n",
        "\n",
        "    avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "    # Printing as training/ validation loss as the model trains\n",
        "\n",
        "    print(f\"Epoch {epoch:03d}: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping conditions\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Best model saved with Val Loss: {best_val_loss:.4f}\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # If the model's validation loss doesn't improve after 10 epochs, the model will automatically trigger early stopping"
      ],
      "metadata": {
        "id": "fwlS-3a9txMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "def hausdorff_distance(pred, target):\n",
        "    pred = pred.squeeze().cpu().numpy()\n",
        "    target = target.squeeze().cpu().numpy()\n",
        "\n",
        "    # Get coordinates of boundary pixels\n",
        "    pred_coords = np.argwhere(pred > 0.5)\n",
        "    target_coords = np.argwhere(target > 0.5)\n",
        "\n",
        "    # Handle empty masks\n",
        "    if len(pred_coords) == 0 or len(target_coords) == 0:\n",
        "        return np.nan  # Return NaN if either mask is empty\n",
        "\n",
        "    # Compute both directions\n",
        "    hd1 = directed_hausdorff(pred_coords, target_coords)[0]\n",
        "    hd2 = directed_hausdorff(target_coords, pred_coords)[0]\n",
        "\n",
        "    return max(hd1, hd2)"
      ],
      "metadata": {
        "id": "63MqJVJ2xSlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(preds, targets, smooth=1e-6):\n",
        "    # Flatten tensors and calculate TP, FP, FN, TN\n",
        "    preds_flat = preds.flatten(1)\n",
        "    targets_flat = targets.flatten(1)\n",
        "\n",
        "    tp = (preds_flat * targets_flat).sum(1)\n",
        "    fp = (preds_flat * (1 - targets_flat)).sum(1)\n",
        "    fn = ((1 - preds_flat) * targets_flat).sum(1)\n",
        "    tn = ((1 - preds_flat) * (1 - targets_flat)).sum(1)\n",
        "\n",
        "    # Standard metrics\n",
        "    metrics = {\n",
        "        'Dice': ((2 * tp + smooth) / (tp + fp + tp + fn + smooth)).mean().item(),\n",
        "        'IoU': ((tp + smooth) / (tp + fp + fn + smooth)).mean().item(),\n",
        "        'Precision': ((tp + smooth) / (tp + fp + smooth)).mean().item(),\n",
        "        'Recall': ((tp + smooth) / (tp + fn + smooth)).mean().item(),\n",
        "        'Specificity': ((tn + smooth) / (tn + fp + smooth)).mean().item(),\n",
        "        'Accuracy': ((tp + tn + smooth) / (tp + tn + fp + fn + smooth)).mean().item(),\n",
        "    }\n",
        "\n",
        "    # Hausdorff Distance (handle batch)\n",
        "    hd_values = []\n",
        "    for p, t in zip(preds, targets):\n",
        "        hd = hausdorff_distance(p, t)\n",
        "        if not np.isnan(hd):\n",
        "            hd_values.append(hd)\n",
        "    metrics['HD95'] = np.percentile(hd_values, 95) if hd_values else np.nan\n",
        "\n",
        "    # Tumor size error\n",
        "    pred_area = preds_flat.sum(1)\n",
        "    target_area = targets_flat.sum(1)\n",
        "    metrics['Size_Error'] = ((pred_area - target_area).abs() / (target_area + smooth)).mean().item()\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "yEQjUo3NxXw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_metrics = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        metrics = calculate_metrics(preds, masks)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "# Aggregate results (ignoring NaN values)\n",
        "final_metrics = {\n",
        "    k: np.nanmean([m[k] for m in all_metrics if not np.isnan(m[k])])\n",
        "    for k in all_metrics[0].keys()\n",
        "}\n"
      ],
      "metadata": {
        "id": "202Y6wrhxaFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Metrics:\")\n",
        "for metric, value in final_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "xpPw5HPzxcgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def bootstrap_ci(metric_values, n_bootstraps=1000, ci=95, seed=42):\n",
        "    \"\"\"Calculate bootstrap confidence intervals\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    bootstrapped_means = []\n",
        "\n",
        "    for _ in tqdm(range(n_bootstraps)):\n",
        "        # Resample with replacement\n",
        "        resampled = np.random.choice(metric_values, size=len(metric_values), replace=True)\n",
        "        bootstrapped_means.append(np.nanmean(resampled))\n",
        "\n",
        "    lower = np.percentile(bootstrapped_means, (100 - ci) / 2)\n",
        "    upper = np.percentile(bootstrapped_means, 100 - (100 - ci) / 2)\n",
        "    return lower, upper\n",
        "\n",
        "# Usage\n",
        "dice_scores = [m['Dice'] for m in all_metrics]\n",
        "dice_ci = bootstrap_ci(dice_scores, ci=95)\n",
        "print(f\"Dice: {np.mean(dice_scores):.3f} ({dice_ci[0]:.3f}-{dice_ci[1]:.3f})\")"
      ],
      "metadata": {
        "id": "PkS-Z0nJxjPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def parametric_ci(metric_values, ci=95):\n",
        "    \"\"\"Calculate parametric CI assuming normal distribution\"\"\"\n",
        "    mean = np.nanmean(metric_values)\n",
        "    sem = stats.sem(metric_values, nan_policy='omit')  # Standard error\n",
        "    ci_val = sem * stats.t.ppf((1 + ci/100) / 2, len(metric_values)-1)\n",
        "    return mean - ci_val, mean + ci_val\n",
        "\n",
        "# Usage\n",
        "iou_scores = [m['IoU'] for m in all_metrics]\n",
        "iou_ci = parametric_ci(iou_scores, ci=95)\n",
        "print(f\"IoU: {np.mean(iou_scores):.3f} ({iou_ci[0]:.3f}-{iou_ci[1]:.3f})\")\n"
      ],
      "metadata": {
        "id": "uzHhu4F2xq43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_with_ci(model, test_loader, device, n_bootstraps=1000):\n",
        "    model.eval()\n",
        "    all_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in test_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            metrics = calculate_metrics(preds, masks)\n",
        "            all_metrics.append(metrics)\n",
        "\n",
        "    # Aggregate metrics\n",
        "    metric_names = all_metrics[0].keys()\n",
        "    results = {}\n",
        "\n",
        "    for name in metric_names:\n",
        "        values = [m[name] for m in all_metrics]\n",
        "\n",
        "        # Use bootstrapping for Dice/IoU/HD95\n",
        "        if name in ['Dice', 'IoU', 'HD95']:\n",
        "            ci = bootstrap_ci(values, n_bootstraps=n_bootstraps)\n",
        "        else:\n",
        "            ci = parametric_ci(values)\n",
        "\n",
        "        results[name] = {\n",
        "            'mean': np.nanmean(values),\n",
        "            'ci_lower': ci[0],\n",
        "            'ci_upper': ci[1],\n",
        "            'ci_method': 'bootstrap' if name in ['Dice', 'IoU', 'HD95'] else 'parametric'\n",
        "        }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "U6JdhgLxxtkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_with_ci(\n",
        "    model=model,\n",
        "    test_loader=test_loader,\n",
        "    device=device,\n",
        "    n_bootstraps=1000  # Reduce to 200-500 for faster testing\n",
        ")\n",
        "\n",
        "# Print formatted results\n",
        "for metric, vals in results.items():\n",
        "    print(f\"{metric}: {vals['mean']:.4f} ({vals['ci_lower']:.4f}-{vals['ci_upper']:.4f}) [CI method: {vals['ci_method']}]\")"
      ],
      "metadata": {
        "id": "joVIG0jDxvSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/U-Net_0.9259.pth'"
      ],
      "metadata": {
        "id": "1usxAcZ0Bxdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), checkpoint_path)\n",
        "print(f\"Model saved to {checkpoint_path}\")"
      ],
      "metadata": {
        "id": "itZG6__Bxw3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}